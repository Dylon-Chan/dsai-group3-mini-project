{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47e1c5a-8fea-4213-aef5-a0e93f606dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: isodate in c:\\users\\cyewp\\miniconda3\\envs\\pds\\lib\\site-packages (0.7.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0c3ea33-72f4-422a-8c59-52e533427fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching most popular videos in SG...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>channel</th>\n",
       "      <th>published_at</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Graham Stephan</td>\n",
       "      <td>2025-02-23T18:00:24Z</td>\n",
       "      <td>Z0QtK1qOnQ0</td>\n",
       "      <td>27</td>\n",
       "      <td>9861550</td>\n",
       "      <td>516948</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Always Cinema</td>\n",
       "      <td>2025-03-04T10:32:18Z</td>\n",
       "      <td>n6My5VNf82c</td>\n",
       "      <td>24</td>\n",
       "      <td>9829575</td>\n",
       "      <td>383944</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>19.0</td>\n",
       "      <td>藏獒加布</td>\n",
       "      <td>2025-02-26T10:00:01Z</td>\n",
       "      <td>1O4vCcabr2w</td>\n",
       "      <td>15</td>\n",
       "      <td>944402</td>\n",
       "      <td>13801</td>\n",
       "      <td>Pets &amp; Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Jay &amp; Sharon</td>\n",
       "      <td>2025-02-20T18:54:38Z</td>\n",
       "      <td>N38sPx5KHiA</td>\n",
       "      <td>23</td>\n",
       "      <td>9419827</td>\n",
       "      <td>619320</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Daniel LaBelle</td>\n",
       "      <td>2025-02-26T15:49:31Z</td>\n",
       "      <td>I7Lv-1GY92M</td>\n",
       "      <td>23</td>\n",
       "      <td>88637924</td>\n",
       "      <td>1764679</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Unnecessary Inventions</td>\n",
       "      <td>2025-02-24T16:53:23Z</td>\n",
       "      <td>5XtALh0y6Ss</td>\n",
       "      <td>24</td>\n",
       "      <td>8781010</td>\n",
       "      <td>631761</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Alan's Universe</td>\n",
       "      <td>2025-03-03T13:00:11Z</td>\n",
       "      <td>stPz9yDqjfI</td>\n",
       "      <td>24</td>\n",
       "      <td>87569873</td>\n",
       "      <td>4093007</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.0</td>\n",
       "      <td>The Daily Ketchup Podcast</td>\n",
       "      <td>2025-03-04T08:52:58Z</td>\n",
       "      <td>oq3ss-RomeA</td>\n",
       "      <td>24</td>\n",
       "      <td>78784</td>\n",
       "      <td>1611</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Various forms of life</td>\n",
       "      <td>2025-02-20T04:40:15Z</td>\n",
       "      <td>vjIsyhsc8bQ</td>\n",
       "      <td>22</td>\n",
       "      <td>780238</td>\n",
       "      <td>12256</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Daily Dose Of Internet</td>\n",
       "      <td>2025-02-28T21:01:56Z</td>\n",
       "      <td>7yYXnS6dvPQ</td>\n",
       "      <td>24</td>\n",
       "      <td>7584736</td>\n",
       "      <td>627220</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    duration                    channel          published_at     video_id  \\\n",
       "31      40.0             Graham Stephan  2025-02-23T18:00:24Z  Z0QtK1qOnQ0   \n",
       "15      11.0              Always Cinema  2025-03-04T10:32:18Z  n6My5VNf82c   \n",
       "30      19.0                       藏獒加布  2025-02-26T10:00:01Z  1O4vCcabr2w   \n",
       "44      15.0               Jay & Sharon  2025-02-20T18:54:38Z  N38sPx5KHiA   \n",
       "33      45.0             Daniel LaBelle  2025-02-26T15:49:31Z  I7Lv-1GY92M   \n",
       "43     100.0     Unnecessary Inventions  2025-02-24T16:53:23Z  5XtALh0y6Ss   \n",
       "14      55.0            Alan's Universe  2025-03-03T13:00:11Z  stPz9yDqjfI   \n",
       "8       64.0  The Daily Ketchup Podcast  2025-03-04T08:52:58Z  oq3ss-RomeA   \n",
       "57      19.0      Various forms of life  2025-02-20T04:40:15Z  vjIsyhsc8bQ   \n",
       "47      22.0     Daily Dose Of Internet  2025-02-28T21:01:56Z  7yYXnS6dvPQ   \n",
       "\n",
       "   category_id     views    likes        category  \n",
       "31          27   9861550   516948       Education  \n",
       "15          24   9829575   383944   Entertainment  \n",
       "30          15    944402    13801  Pets & Animals  \n",
       "44          23   9419827   619320          Comedy  \n",
       "33          23  88637924  1764679          Comedy  \n",
       "43          24   8781010   631761   Entertainment  \n",
       "14          24  87569873  4093007   Entertainment  \n",
       "8           24     78784     1611   Entertainment  \n",
       "57          22    780238    12256  People & Blogs  \n",
       "47          24   7584736   627220   Entertainment  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Comedy                   8\n",
       "Education                2\n",
       "Entertainment           22\n",
       "Film & Animation         1\n",
       "Gaming                   4\n",
       "Music                    9\n",
       "News & Politics          5\n",
       "People & Blogs          12\n",
       "Pets & Animals           1\n",
       "Science & Technology     1\n",
       "Sports                  10\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully exported to popular_videos.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "import isodate\n",
    "\n",
    "# Define your YouTube API key here\n",
    "API_KEY = 'Your Key'\n",
    "\n",
    "# Initialize the YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "def get_video_categories(region_code='SG'):\n",
    "    categories = {}\n",
    "    try:\n",
    "        # Request video categories for the specified region\n",
    "        request = youtube.videoCategories().list(\n",
    "            part=\"snippet\",\n",
    "            regionCode=region_code\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Map categoryId to category title\n",
    "        for item in response['items']:\n",
    "            categories[item['id']] = item['snippet']['title']\n",
    "\n",
    "        return categories\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching video categories: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_most_popular_videos(region_code='SG', max_results=100):\n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Request the most popular videos for the specified region\n",
    "            request = youtube.videos().list(\n",
    "                part=\"snippet,statistics,contentDetails\",\n",
    "                chart=\"mostPopular\",\n",
    "                regionCode=region_code,  # Change to any country code like 'IN', 'GB', 'US'\n",
    "                maxResults=100,  # Maximum number of videos per request (max: 50)\n",
    "                pageToken=next_page_token  # For pagination (nextPageToken)\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            # Extract video details from the response\n",
    "            for item in response['items']:\n",
    "                video_details = {\n",
    "                    #'title': item['snippet']['title'],\n",
    "                    #'description': item['snippet']['description'],\n",
    "                    'duration': item['contentDetails']['duration'],\n",
    "                    'channel': item['snippet']['channelTitle'],\n",
    "                    'published_at': item['snippet']['publishedAt'],\n",
    "                    'video_id': item['id'],\n",
    "                    'category_id': item['snippet'].get('categoryId', 'N/A'),\n",
    "                    'views': item['statistics'].get('viewCount', 'N/A'),\n",
    "                    'likes': item['statistics'].get('likeCount', 'N/A'),\n",
    "                    #'dislikes': item['statistics'].get('dislikeCount', 'N/A',),\n",
    "                }\n",
    "                videos.append(video_details)\n",
    "\n",
    "            # If a nextPageToken is returned, keep fetching the next page of results\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "            if not next_page_token or len(videos) >= max_results:\n",
    "                break  # Stop if there are no more pages or we've reached max_results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    return videos\n",
    "\n",
    "def convert_to_dataframe(videos, categories):\n",
    "    # Convert the list of video data to a pandas DataFrame\n",
    "    df = pd.DataFrame(videos)\n",
    "\n",
    "    # Map categoryId to category title\n",
    "    df['category'] = df['category_id'].map(categories)\n",
    "\n",
    "    # If you want to add a 'Video URL' column based on the video_id\n",
    " #   df['Video URL'] = 'https://www.youtube.com/watch?v=' + df['video_id']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_to_csv(df, filename='popular_videos.csv'):\n",
    "    try:\n",
    "        # Export the DataFrame to CSV\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"Data has been successfully exported to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while exporting data to CSV: {e}\")\n",
    "\n",
    "def iso8601_to_seconds(duration):\n",
    "    # Parse the ISO 8601 duration string to a timedelta object\n",
    "    td = isodate.parse_duration(duration)\n",
    "    # Return the total duration in seconds\n",
    "    return td.total_seconds()\n",
    "\n",
    "def main():\n",
    "    # Get the top 20 most popular videos in the US (can be changed to other regions like 'IN', 'GB', etc.)\n",
    "    region_code = 'SG'  # Change this to get popular videos from another region\n",
    "    max_results = 100  # Set the number of videos you want to fetch\n",
    "    print(f\"Fetching most popular videos in {region_code}...\")\n",
    "\n",
    "    # Step 1: Fetch video categories\n",
    "    categories = get_video_categories(region_code)\n",
    "\n",
    "    # Step 2: Fetch popular videos\n",
    "    popular_videos = get_most_popular_videos(region_code, max_results)\n",
    "\n",
    "    # Step 3: Convert the results into a DataFrame\n",
    "    df = convert_to_dataframe(popular_videos, categories)\n",
    "\n",
    "    # Display the DataFrame (optional)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    # Convert iso duration to sec\n",
    "    df['duration'] = df['duration'].apply(iso8601_to_seconds)\n",
    "   \n",
    "    # Show the columns \n",
    " \n",
    "    display(df.sort_values(\"views\",ascending=False).head(10))\n",
    "\n",
    "    display(df.groupby([\"category\"]).size())\n",
    "\n",
    "    #display(df[:]['duration'])\n",
    "    # Step 4: Export the results to a CSV file\n",
    "    export_to_csv(df, 'popular_videos.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d491d3-dccf-4310-b81c-365259eeb61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
